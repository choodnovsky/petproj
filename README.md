## –ü–æ—à–∞–≥–æ–≤—ã–π —Ä–µ—Ü–µ–ø—Ç

1. `docker-compose up -d --build` –∑–∞–ø—É—Å–∫ –∑–æ–æ–ø–∞—Ä–∫–∞
2. `bash clean.sh`  (–æ—Å—Ç–∞–≤–∞–Ω–ª–∏–≤–∞–µ–º –∏ —É–±–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –∏ –≤—Å–µ —á—Ç–æ —Å –Ω–∏–º–∏ —Å–≤—è–∑–∞–Ω–æ, —á—Ç–æ–±—ã –Ω–µ –∑–∞–Ω–∏–º–∞—Ç—å —Ä–µ—Å—É—Ä—Å—ã)
3. –î–ª—è –≤–æ—Å—Å–∞—Ç–Ω–æ–≤–ª–µ–Ω–∏—è –±–∞–∑—ã –≤ –ø–æ—Å—Ç–≥—Ä–µ—Å –ø–µ—Ä–µ—Ö–æ–¥–∏–º –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä `docker exec -it postgres psql -U postgres -c 'CREATE DATABASE dvdrental;'`
4. —Ç–∞–º –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –±–∞–∑—É `docker exec -it postgres pg_restore -U postgres -d dvdrental --verbose /upload_pg/dvdrental_new.tar`
–≥–¥–µ:
- -U —ç—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
- -d —ç—Ç–æ –∏–º—è –±–∞–∑—ã
5. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∫–∏–µ –µ—Å—Ç—å –º–æ–¥–µ–ª–∏ –≤ –∫–æ–Ω—Ç–π–Ω–µ—Ä–µ —Å –æ–ª–ª–∞–º–æ–π `docker exec -it ollama ollama list` —Ç–∞–º –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø—É—Å—Ç–æ —Ç–∏–ø–æ —Ç–æ–≥–æ `{"models":[]} `
6. –ó–∞–≥—Ä—É–∑–∏–º –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –º–æ–¥–µ–ª—å `docker exec -it ollama ollama pull mistral`

____
–ö–∞–∫ —É—Å–∏–ª–∏—Ç—å RAG:
1.	üì• –ò–Ω–≥–µ—Å—Ç –Ω–æ–≤—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–∏–∑ –≤–∏–∫–∏).
2.  üß† –£–ª—É—á—à–µ–Ω–∏–µ chunking ‚Äî –∞–¥–∞–ø—Ç–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–∞ –∫ —Å–º—ã—Å–ª—É.
3.	üîç –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ç–æ–ø-k –ø–æ–∏—Å–∫–∞ –∏ reranking.
4.	üìä –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ + –≤–∞–ª–∏–¥–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å –ø–æ–º–æ—â—å—é –º–µ—Ç—Ä–∏–∫ –∏–ª–∏ —Ñ–∏–¥–±—ç–∫–∞).
5.	üõ°Ô∏è –§–∏–ª—å—Ç—Ä—ã: –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º, –ø—Ä–∞–≤–∞–º –¥–æ—Å—Ç—É–ø–∞ –∏ —Ç.–¥.

##### 1.–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–∑–∞–º–µ–Ω–∞ lotr.txt –Ω–∞ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—É—é –≤–∏–∫–∏)  

–¶–µ–ª—å: –∑–∞–º–µ–Ω–∏—Ç—å data/lotr.txt –Ω–∞ –∑–∞–≥—Ä—É–∑–∫—É –≤—Å–µ—Ö –Ω—É–∂–Ω—ã—Ö –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

---

–®–∞–≥–∏:  
–∞) –°–æ–±–µ—Ä–∞—Ç—å –≤—Å—é –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—É—é –≤–∏–∫–∏:  
- –ï—Å–ª–∏ –æ–Ω–∞ –≤ –≤–∏–¥–µ HTML/Markdown/Confluence/Notion/Google Docs –∏ —Ç.–ø. ‚Äî —Å–Ω–∞—á–∞–ª–∞ –≤—ã–≥—Ä—É–∑–∏—Ç—å —Ç–µ–∫—Å—Ç.   
- –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—Å–µ —Å—Ç–∞—Ç—å–∏ –≤ –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ .txt –∏–ª–∏ .md —Ñ–∞–π–ª–æ–≤.  
–±) –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤—Å—ë –≤ –æ–¥–∏–Ω —Ñ–∞–π–ª data/wiki_corpus.txt –∏–ª–∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–æ—Ñ–∞–π–ª–æ–≤–æ ‚Äî Chroma –ø–æ–¥–¥—Ä–∂–∏–≤–∞–µ—Ç –æ–±–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞.  
–≤) –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤ ingest.py –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å –∫ —ç—Ç–∏–º —Ñ–∞–π–ª–∞–º. –ü—Ä–∏–º–µ—Ä:

```angular2html
persist_directory = "chroma_db"
source_directory = "data/wiki"

loader = TextLoader(source_directory)
documents = loader.load()
```
–ò–ª–∏ —á–µ—Ä–µ–∑ LangChain DirectoryLoader, –µ—Å–ª–∏ —Ñ–∞–π–ª–æ–≤ –º–Ω–æ–≥–æ:

```angular2html
from langchain.document_loaders import DirectoryLoader
loader = DirectoryLoader(source_directory, glob="**/*.txt")
```
##### 2. –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤ ChromaDB (–¥–æ–±–∞–≤–ª—è–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π –≤–∏–∫–∏)   
–¶–µ–ª—å: –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π –≤–∏–∫–∏ –≤ –≤–µ–∫—Ç–æ—Ä—ã –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏—Ö –≤ ChromaDB.

----
–®–∞–≥–∏:  
–∞) –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∫–æ–¥ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤. –ù–∞–ø—Ä–∏–º–µ—Ä:  
```angular2html
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma
from langchain.document_loaders import DirectoryLoader, TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
loader = DirectoryLoader("data/wiki", glob="**/*.txt")
documents = loader.load()

# 2. –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏
text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
docs = text_splitter.split_documents(documents)

# 3. –í–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏
embedding = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

# 4. –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –≤ Chroma
db = Chroma.from_documents(
    documents=docs,
    embedding=embedding,
    persist_directory="chroma_db"
)
db.persist()
```
üß† –í–∞–∂–Ω–æ:  
- –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ `persist_directory="chroma_db"` ‚Äî —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π, –∫–æ—Ç–æ—Ä—É—é –º–æ–Ω—Ç–∏—Ä—É–µ—Ç —Ç–≤–æ–π Docker-–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä chroma.  
- –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –º–æ–¥–µ–ª—å `all-MiniLM-L6-v2` —Å–∫–∞—á–∏–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ ‚Äî –æ–Ω–∞ –Ω—É–∂–Ω–∞ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.  
---- 


‚úÖ –ü–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç—Ç–æ–≥–æ —à–∞–≥–∞, –≤ ChromaDB –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –≤—Å–µ–π –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π –≤–∏–∫–∏.  

##### 3. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ ChromaDB –ø–æ –∑–∞–ø—Ä–æ—Å—É   
–¶–µ–ª—å: –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞ ‚Äî –Ω–∞–π—Ç–∏ –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∏–∑ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π –≤–∏–∫–∏ –∏ –ø–µ—Ä–µ–¥–∞—Ç—å –∏—Ö –º–æ–¥–µ–ª–∏.

-------
```angular2html
from langchain.vectorstores import Chroma
from langchain.embeddings import HuggingFaceEmbeddings

# 1. –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ —É–∂–µ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–π –±–∞–∑–µ
embedding = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
db = Chroma(
    persist_directory="chroma_db",
    embedding_function=embedding
)

# 2. –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
def get_relevant_docs(query, k=3):
    results = db.similarity_search_with_score(query, k=k)
    docs = [doc.page_content for doc, score in results]
    return "\n".join(docs)

# –ü—Ä–∏–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞
query = "–ö–∞–∫ —É—Å—Ç—Ä–æ–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–π –≤ –Ω–∞—à–µ–π –∫–æ–º–ø–∞–Ω–∏–∏?"
context = get_relevant_docs(query)
print(context)
```
üß† –ù–∞ —á—Ç–æ –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ:  
- `similarity_search_with_score` –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–∞—Ä—ã (Document, score) ‚Äî —Ç–µ–∫—Å—Ç + —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ.  
- –ú–µ—Ç–æ–¥ `page_content` –¥–æ—Å—Ç–∞—ë—Ç —Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞.  
- `k-3` ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤, –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å.  

‚úÖ –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ —à–∞–≥–∞ —É –Ω–∞—Å –±—É–¥–µ—Ç —Ç–µ–∫—Å—Ç-–∫–æ–Ω—Ç–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–Ω–æ –æ—Ç–¥–∞—Ç—å –≤ –ø—Ä–æ–º–ø—Ç Ollama.  

##### 4. –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –µ–≥–æ –≤ –º–æ–¥–µ–ª—å Ollama   
–¶–µ–ª—å: —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç, –∫—É–¥–∞ –ø–æ–¥—Å—Ç–∞–≤–∏–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (–∏–∑ ChromaDB) –∏ —Å–∞–º –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, —á—Ç–æ–±—ã Ollama –º–æ–≥–ª–∞ –¥–∞—Ç—å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç.

---

üìå –®–∞–±–ª–æ–Ω –ø—Ä–æ–º–ø—Ç–∞:  
```angular2html
def build_prompt(context: str, question: str) -> str:
    return f"""–¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –æ—Ç–≤–µ—á–∞—é—â–∏–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏.

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
\"\"\"
{context}
\"\"\"

–í–æ–ø—Ä–æ—Å: {question}
–û—Ç–≤–µ—Ç:"""
```
üìå –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ Ollama:  
```angular2html
import requests
import json

def ask_ollama(prompt: str, model_name="llama3"):
    response = requests.post(
        "http://localhost:11434/api/generate",
        json={
            "model": model_name,
            "prompt": prompt,
            "stream": False
        }
    )
    if response.status_code == 200:
        return response.json().get("response", "")
    else:
        raise Exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ Ollama: {response.status_code} - {response.text}")
```
‚úÖ –ò—Ç–æ–≥–æ–≤–∞—è —Å–≤—è–∑–∫–∞:

```angular2html
query = "–ö–∞–∫–∏–µ —ç—Ç–∞–ø—ã –≤–∫–ª—é—á–∞–µ—Ç –ø—Ä–æ—Ü–µ–¥—É—Ä–∞ –Ω–∞–π–º–∞ –Ω–æ–≤—ã—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤?"
context = get_relevant_docs(query)
prompt = build_prompt(context, query)
response = ask_ollama(prompt)
print(response)
```

üìé –†–µ–∑—É–ª—å—Ç–∞—Ç: –ú–æ–¥–µ–ª—å –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–µ ‚Äú–∏–∑ –≥–æ–ª–æ–≤—ã‚Äù, –∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.  

##### 5. –ö–∞–∫ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—É—é –≤–∏–∫–∏ –≤ ChromaDB  

---

‚úÖ –ß—Ç–æ –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å:  
1. –°–æ–±—Ä–∞—Ç—å —Ç–µ–∫—Å—Ç—ã –∏–∑ –≤–∏–∫–∏ –≤ –æ–¥–Ω–æ–º –º–µ—Å—Ç–µ (—Ñ–∞–π–ª—ã .md, .txt, .html, .pdf, –∏–ª–∏ –¥–∞–∂–µ .docx)
2. –†–∞–∑–±–∏—Ç—å –∏—Ö –Ω–∞ —É–¥–æ–±–Ω—ã–µ —á–∞–Ω–∫–∏ (–¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤)
3. –°–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ 
4. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—Å—ë —ç—Ç–æ –≤ ChromaDB
----
üß± –®–∞–≥ 1: –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö  
–°–æ–±–µ—Ä–∏ –≤—Å—ë, —á—Ç–æ –µ—Å—Ç—å –∏–∑ –≤–∏–∫–∏, –≤ –æ–¥–Ω—É –ø–∞–ø–∫—É, –Ω–∞–ø—Ä–∏–º–µ—Ä ./data/wiki/.  
–§–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–æ–≤: .txt, .md, .docx, .pdf ‚Äî –≤—Å—ë –ø–æ–¥—Ö–æ–¥–∏—Ç. –ß–µ–º —á–∏—â–µ, —Ç–µ–º –ª—É—á—à–µ.   

üßπ –®–∞–≥ 2: –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏  
```angular2html
from langchain.text_splitter import RecursiveCharacterTextSplitter

def split_text(text, chunk_size=500, chunk_overlap=50):
    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
    return splitter.split_text(text)
```
üß† –®–∞–≥ 3: –ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤  
```angular2html
from sentence_transformers import SentenceTransformer

embed_model = SentenceTransformer("all-MiniLM-L6-v2")  # –∏–ª–∏ "all-mpnet-base-v2"
```
üì¶ –®–∞–≥ 4: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ ChromaDB  
```angular2html
import os

def load_and_index_files(folder_path):
    for filename in os.listdir(folder_path):
        filepath = os.path.join(folder_path, filename)
        with open(filepath, "r", encoding="utf-8") as f:
            text = f.read()
            chunks = split_text(text)
            add_to_chroma(chunks, filename)

# –ó–∞–≥—Ä—É–∑–∫–∞
load_and_index_files("./data/wiki/")
```
‚úÖ –ì–æ—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π –≤–∏–∫–∏ –≤ ChromaDB  
```angular2html
# rag_indexer.py

import os
import chromadb
from sentence_transformers import SentenceTransformer
from langchain.text_splitter import RecursiveCharacterTextSplitter

# üîπ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–µ–π
embed_model = SentenceTransformer("all-MiniLM-L6-v2")
text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)

# üîπ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ ChromaDB
chroma_client = chromadb.PersistentClient(path="./chroma")
collection = chroma_client.get_or_create_collection(name="wiki_docs")

# üîπ –§—É–Ω–∫—Ü–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
def split_text(text):
    return text_splitter.split_text(text)

def add_to_chroma(docs, source_name):
    for i, doc in enumerate(docs):
        embedding = embed_model.encode(doc).tolist()
        collection.add(
            documents=[doc],
            embeddings=[embedding],
            metadatas=[{"source": source_name, "index": i}],
            ids=[f"{source_name}_{i}"]
        )

def load_and_index_files(folder_path="./data/wiki/"):
    for filename in os.listdir(folder_path):
        filepath = os.path.join(folder_path, filename)
        if filename.endswith((".txt", ".md")):
            with open(filepath, "r", encoding="utf-8") as f:
                text = f.read()
                chunks = split_text(text)
                add_to_chroma(chunks, filename)
                print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {filename} ({len(chunks)} —á–∞–Ω–∫–æ–≤)")
        else:
            print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω (–Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç): {filename}")

# üîπ –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞
if __name__ == "__main__":
    load_and_index_files()
    print("‚úÖ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
```
