## –ü–æ—à–∞–≥–æ–≤—ã–π —Ä–µ—Ü–µ–ø—Ç

1. `docker-compose up -d --build` –∑–∞–ø—É—Å–∫ –∑–æ–æ–ø–∞—Ä–∫–∞
2. `bash clean.sh`  (–æ—Å—Ç–∞–≤–∞–Ω–ª–∏–≤–∞–µ–º –∏ —É–±–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –∏ –≤—Å–µ —á—Ç–æ —Å –Ω–∏–º–∏ —Å–≤—è–∑–∞–Ω–æ, —á—Ç–æ–±—ã –Ω–µ –∑–∞–Ω–∏–º–∞—Ç—å —Ä–µ—Å—É—Ä—Å—ã)
3. –î–ª—è –≤–æ—Å—Å–∞—Ç–Ω–æ–≤–ª–µ–Ω–∏—è –±–∞–∑—ã –≤ –ø–æ—Å—Ç–≥—Ä–µ—Å –ø–µ—Ä–µ—Ö–æ–¥–∏–º –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä `docker exec -it postgres psql -U postgres -c 'CREATE DATABASE dvdrental;'`
4. —Ç–∞–º –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –±–∞–∑—É `docker exec -it postgres pg_restore -U postgres -d dvdrental --verbose /upload_pg/dvdrental_new.tar`
–≥–¥–µ:
- -U —ç—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
- -d —ç—Ç–æ –∏–º—è –±–∞–∑—ã
5. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∫–∏–µ –µ—Å—Ç—å –º–æ–¥–µ–ª–∏ –≤ –∫–æ–Ω—Ç–π–Ω–µ—Ä–µ —Å –æ–ª–ª–∞–º–æ–π `docker exec -it ollama ollama list` —Ç–∞–º –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø—É—Å—Ç–æ —Ç–∏–ø–æ —Ç–æ–≥–æ `{"models":[]} `
6. –ó–∞–≥—Ä—É–∑–∏–º –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –º–æ–¥–µ–ª—å `docker exec -it ollama ollama pull mistral`

____
–ö–∞–∫ —É—Å–∏–ª–∏—Ç—å RAG:
1.	üì• –ò–Ω–≥–µ—Å—Ç –Ω–æ–≤—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–∏–∑ –≤–∏–∫–∏).
2.  üß† –£–ª—É—á—à–µ–Ω–∏–µ chunking ‚Äî –∞–¥–∞–ø—Ç–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–∞ –∫ —Å–º—ã—Å–ª—É.
3.	üîç –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ç–æ–ø-k –ø–æ–∏—Å–∫–∞ –∏ reranking.
4.	üìä –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ + –≤–∞–ª–∏–¥–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å –ø–æ–º–æ—â—å—é –º–µ—Ç—Ä–∏–∫ –∏–ª–∏ —Ñ–∏–¥–±—ç–∫–∞).
5.	üõ°Ô∏è –§–∏–ª—å—Ç—Ä—ã: –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º, –ø—Ä–∞–≤–∞–º –¥–æ—Å—Ç—É–ø–∞ –∏ —Ç.–¥.

##### 1.–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–∑–∞–º–µ–Ω–∞ lotr.txt –Ω–∞ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—É—é –≤–∏–∫–∏)  

–¶–µ–ª—å: –∑–∞–º–µ–Ω–∏—Ç—å data/lotr.txt –Ω–∞ –∑–∞–≥—Ä—É–∑–∫—É –≤—Å–µ—Ö –Ω—É–∂–Ω—ã—Ö –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

---

–®–∞–≥–∏:  
–∞) –°–æ–±–µ—Ä–∞—Ç—å –≤—Å—é –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—É—é –≤–∏–∫–∏:  
- –ï—Å–ª–∏ –æ–Ω–∞ –≤ –≤–∏–¥–µ HTML/Markdown/Confluence/Notion/Google Docs –∏ —Ç.–ø. ‚Äî —Å–Ω–∞—á–∞–ª–∞ –≤—ã–≥—Ä—É–∑–∏—Ç—å —Ç–µ–∫—Å—Ç.   
- –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—Å–µ —Å—Ç–∞—Ç—å–∏ –≤ –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ .txt –∏–ª–∏ .md —Ñ–∞–π–ª–æ–≤.  
–±) –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤—Å—ë –≤ –æ–¥–∏–Ω —Ñ–∞–π–ª data/wiki_corpus.txt –∏–ª–∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–æ—Ñ–∞–π–ª–æ–≤–æ ‚Äî Chroma –ø–æ–¥–¥—Ä–∂–∏–≤–∞–µ—Ç –æ–±–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞.  
–≤) –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤ ingest.py –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å –∫ —ç—Ç–∏–º —Ñ–∞–π–ª–∞–º. –ü—Ä–∏–º–µ—Ä:

```angular2html
persist_directory = "chroma_db"
source_directory = "data/wiki"

loader = TextLoader(source_directory)
documents = loader.load()
```
–ò–ª–∏ —á–µ—Ä–µ–∑ LangChain DirectoryLoader, –µ—Å–ª–∏ —Ñ–∞–π–ª–æ–≤ –º–Ω–æ–≥–æ:

```angular2html
from langchain.document_loaders import DirectoryLoader
loader = DirectoryLoader(source_directory, glob="**/*.txt")
```
##### 2. –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤ ChromaDB (–¥–æ–±–∞–≤–ª—è–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π –≤–∏–∫–∏)   
–¶–µ–ª—å: –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π –≤–∏–∫–∏ –≤ –≤–µ–∫—Ç–æ—Ä—ã –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏—Ö –≤ ChromaDB.

----
–®–∞–≥–∏:  
–∞) –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∫–æ–¥ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤. –ù–∞–ø—Ä–∏–º–µ—Ä:  
```angular2html
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma
from langchain.document_loaders import DirectoryLoader, TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
loader = DirectoryLoader("data/wiki", glob="**/*.txt")
documents = loader.load()

# 2. –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏
text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
docs = text_splitter.split_documents(documents)

# 3. –í–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏
embedding = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

# 4. –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –≤ Chroma
db = Chroma.from_documents(
    documents=docs,
    embedding=embedding,
    persist_directory="chroma_db"
)
db.persist()
```
üß† –í–∞–∂–Ω–æ:  
- –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ `persist_directory="chroma_db"` ‚Äî —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π, –∫–æ—Ç–æ—Ä—É—é –º–æ–Ω—Ç–∏—Ä—É–µ—Ç —Ç–≤–æ–π Docker-–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä chroma.  
- –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –º–æ–¥–µ–ª—å `all-MiniLM-L6-v2` —Å–∫–∞—á–∏–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ ‚Äî –æ–Ω–∞ –Ω—É–∂–Ω–∞ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.  
---- 


‚úÖ –ü–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç—Ç–æ–≥–æ —à–∞–≥–∞, –≤ ChromaDB –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –≤—Å–µ–π –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π –≤–∏–∫–∏.  

##### 3. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ ChromaDB –ø–æ –∑–∞–ø—Ä–æ—Å—É   
–¶–µ–ª—å: –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞ ‚Äî –Ω–∞–π—Ç–∏ –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∏–∑ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π –≤–∏–∫–∏ –∏ –ø–µ—Ä–µ–¥–∞—Ç—å –∏—Ö –º–æ–¥–µ–ª–∏.

-------
```angular2html
from langchain.vectorstores import Chroma
from langchain.embeddings import HuggingFaceEmbeddings

# 1. –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ —É–∂–µ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–π –±–∞–∑–µ
embedding = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
db = Chroma(
    persist_directory="chroma_db",
    embedding_function=embedding
)

# 2. –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
def get_relevant_docs(query, k=3):
    results = db.similarity_search_with_score(query, k=k)
    docs = [doc.page_content for doc, score in results]
    return "\n".join(docs)

# –ü—Ä–∏–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞
query = "–ö–∞–∫ —É—Å—Ç—Ä–æ–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–π –≤ –Ω–∞—à–µ–π –∫–æ–º–ø–∞–Ω–∏–∏?"
context = get_relevant_docs(query)
print(context)
```
üß† –ù–∞ —á—Ç–æ –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ:  
- `similarity_search_with_score` –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–∞—Ä—ã (Document, score) ‚Äî —Ç–µ–∫—Å—Ç + —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ.  
- –ú–µ—Ç–æ–¥ `page_content` –¥–æ—Å—Ç–∞—ë—Ç —Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞.  
- `k-3` ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤, –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å.  

‚úÖ –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ —à–∞–≥–∞ —É –Ω–∞—Å –±—É–¥–µ—Ç —Ç–µ–∫—Å—Ç-–∫–æ–Ω—Ç–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–Ω–æ –æ—Ç–¥–∞—Ç—å –≤ –ø—Ä–æ–º–ø—Ç Ollama.  

##### 4. –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –µ–≥–æ –≤ –º–æ–¥–µ–ª—å Ollama   
–¶–µ–ª—å: —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç, –∫—É–¥–∞ –ø–æ–¥—Å—Ç–∞–≤–∏–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (–∏–∑ ChromaDB) –∏ —Å–∞–º –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, —á—Ç–æ–±—ã Ollama –º–æ–≥–ª–∞ –¥–∞—Ç—å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç.

---

üìå –®–∞–±–ª–æ–Ω –ø—Ä–æ–º–ø—Ç–∞:  
```angular2html
def build_prompt(context: str, question: str) -> str:
    return f"""–¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –æ—Ç–≤–µ—á–∞—é—â–∏–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏.

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
\"\"\"
{context}
\"\"\"

–í–æ–ø—Ä–æ—Å: {question}
–û—Ç–≤–µ—Ç:"""
```
üìå –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ Ollama:  
```angular2html
import requests
import json

def ask_ollama(prompt: str, model_name="llama3"):
    response = requests.post(
        "http://localhost:11434/api/generate",
        json={
            "model": model_name,
            "prompt": prompt,
            "stream": False
        }
    )
    if response.status_code == 200:
        return response.json().get("response", "")
    else:
        raise Exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ Ollama: {response.status_code} - {response.text}")
```
‚úÖ –ò—Ç–æ–≥–æ–≤–∞—è —Å–≤—è–∑–∫–∞:

```angular2html
query = "–ö–∞–∫–∏–µ —ç—Ç–∞–ø—ã –≤–∫–ª—é—á–∞–µ—Ç –ø—Ä–æ—Ü–µ–¥—É—Ä–∞ –Ω–∞–π–º–∞ –Ω–æ–≤—ã—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤?"
context = get_relevant_docs(query)
prompt = build_prompt(context, query)
response = ask_ollama(prompt)
print(response)
```

üìé –†–µ–∑—É–ª—å—Ç–∞—Ç: –ú–æ–¥–µ–ª—å –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–µ ‚Äú–∏–∑ –≥–æ–ª–æ–≤—ã‚Äù, –∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.  

##### 5. –ö–∞–∫ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—É—é –≤–∏–∫–∏ –≤ ChromaDB  

---

‚úÖ –ß—Ç–æ –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å:  
1. –°–æ–±—Ä–∞—Ç—å —Ç–µ–∫—Å—Ç—ã –∏–∑ –≤–∏–∫–∏ –≤ –æ–¥–Ω–æ–º –º–µ—Å—Ç–µ (—Ñ–∞–π–ª—ã .md, .txt, .html, .pdf, –∏–ª–∏ –¥–∞–∂–µ .docx)
2. –†–∞–∑–±–∏—Ç—å –∏—Ö –Ω–∞ —É–¥–æ–±–Ω—ã–µ —á–∞–Ω–∫–∏ (–¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤)
3. –°–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ 
4. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—Å—ë —ç—Ç–æ –≤ ChromaDB
5. –ü–æ–¥—Ç—è–Ω—É—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ø–∞—Ä—ã –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç. –ë—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç–∏ –ø–∞—Ä—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏–ª–∏  
–ø–æ–¥–±–æ—Ä–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞. –ú—ã –º–æ–∂–µ–º –≤–∫–ª—é—á–∏—Ç—å —ç—Ç–∏ –¥–∞–Ω–Ω—ã–µ –∫–∞–∫ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–ª–∏ –¥–∞–∂–µ –Ω–∞–ø—Ä—è–º—É—é –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–æ–≤.
----
üß± –®–∞–≥ 1: –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö  
–°–æ–±–µ—Ä–∏ –≤—Å—ë, —á—Ç–æ –µ—Å—Ç—å –∏–∑ –≤–∏–∫–∏, –≤ –æ–¥–Ω—É –ø–∞–ø–∫—É, –Ω–∞–ø—Ä–∏–º–µ—Ä ./data/wiki/.  
–§–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–æ–≤: .txt, .md, .docx, .pdf ‚Äî –≤—Å—ë –ø–æ–¥—Ö–æ–¥–∏—Ç. –ß–µ–º —á–∏—â–µ, —Ç–µ–º –ª—É—á—à–µ.   

üßπ –®–∞–≥ 2: –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏  
```angular2html
from langchain.text_splitter import RecursiveCharacterTextSplitter

def split_text(text, chunk_size=1000, chunk_overlap=300):
    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
    return splitter.split_text(text)
```
üß† –®–∞–≥ 3: –ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤  
```angular2html
from sentence_transformers import SentenceTransformer

embed_model = SentenceTransformer("all-MiniLM-L6-v2")  # –∏–ª–∏ "all-mpnet-base-v2"
```
üì¶ –®–∞–≥ 4: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ ChromaDB  
```angular2html
import os

def load_and_index_files(folder_path):
    for filename in os.listdir(folder_path):
        filepath = os.path.join(folder_path, filename)
        with open(filepath, "r", encoding="utf-8") as f:
            text = f.read()
            chunks = split_text(text)
            add_to_chroma(chunks, filename)

# –ó–∞–≥—Ä—É–∑–∫–∞
load_and_index_files("./data/wiki/")
```
‚úÖ C–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π –≤–∏–∫–∏ –≤ ChromaDB  
```angular2html
import os
import chromadb
from sentence_transformers import SentenceTransformer
from langchain.text_splitter import RecursiveCharacterTextSplitter
from tqdm import tqdm

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–µ–π
embed_model = SentenceTransformer("all-MiniLM-L6-v2")  # 384-–º–µ—Ä–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=400)

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ ChromaDB
client = chromadb.HttpClient(host="localhost", port=8000)
collection_name = "wiki_docs"

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
try:
    collection = client.get_collection(collection_name)
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
    if collection and collection.metadata and 'dimension' in collection.metadata:
        expected_dim = collection.metadata["dimension"]
    else:
        expected_dim = None

    actual_dim = embed_model.get_sentence_embedding_dimension()

    if expected_dim and actual_dim != expected_dim:
        print(f"‚ö†Ô∏è –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ ({actual_dim}) –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å—é –∫–æ–ª–ª–µ–∫—Ü–∏–∏ ({expected_dim})")
        print("üîÅ –£–¥–∞–ª—è–µ–º –∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º –∫–æ–ª–ª–µ–∫—Ü–∏—é...")
        client.delete_collection(collection_name)
        collection = client.create_collection(collection_name)
    else:
        print("‚úÖ –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å–æ–≤–ø–∞–¥–∞–µ—Ç –∏–ª–∏ –∫–æ–ª–ª–µ–∫—Ü–∏—è –µ—â—ë –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")

except chromadb.errors.NotFoundError:
    print("üìÅ –ö–æ–ª–ª–µ–∫—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ ‚Äî —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é")
    collection = client.create_collection(collection_name)


# --- –§—É–Ω–∫—Ü–∏–∏ ---
def split_text(text):
    return text_splitter.split_text(text)

def add_to_chroma(docs, source_name):
    print(f"üîπ –î–æ–±–∞–≤–ª—è–µ–º {len(docs)} —á–∞–Ω–∫–æ–≤ –∏–∑ {source_name}")
    for i, doc in tqdm(enumerate(docs), total=len(docs), desc=f"üì• {source_name}"):
        embedding = embed_model.encode(doc).tolist()
        collection.add(
            documents=[doc],
            embeddings=[embedding],
            metadatas=[{"source": source_name, "index": i}],
            ids=[f"{source_name}_{i}"]
        )

def load_and_index_files(folder_path="../data/wiki/"):
    for filename in os.listdir(folder_path):
        filepath = os.path.join(folder_path, filename)
        if filename.endswith((".txt", ".md")):
            with open(filepath, "r", encoding="utf-8") as f:
                text = f.read()
                chunks = split_text(text)
                add_to_chroma(chunks, filename)
                print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {filename} ({len(chunks)} —á–∞–Ω–∫–æ–≤)")
        else:
            print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω (–Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç): {filename}")


# üîπ –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞
if __name__ == "__main__":
    load_and_index_files()
    print("‚úÖ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
```
‚úÖ C–∫—Ä–∏–ø—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç –º–æ–¥–µ–ª–∏
```angular2html
import json
from sentence_transformers import SentenceTransformer
import chromadb
from tqdm import tqdm
import argparse
import ollama

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
context = ""  # –ù–∞—á–∞–ª—å–Ω—ã–π –ø—É—Å—Ç–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç


# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ JSON —Ñ–∞–π–ª–∞
def load_qa_pairs(json_file):
    with open(json_file, "r", encoding="utf-8") as file:
        qa_pairs = json.load(file)
    return qa_pairs


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
def update_context(question, answer):
    global context
    context += f"–í–æ–ø—Ä–æ—Å: {question}\n–û—Ç–≤–µ—Ç: {answer}\n---\n"  # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å –∏ –æ—Ç–≤–µ—Ç


# –ó–∞–ø—Ä–æ—Å –≤ ChromaDB
def query_chromadb(collection: str, question: str, top_k: int = 4):
    # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Chroma
    client = chromadb.HttpClient(host="localhost", port=8000)
    collection = client.get_collection(collection)

    # –≠–º–±–µ–¥–¥–∏–Ω–≥ –≤–æ–ø—Ä–æ—Å–∞
    model = SentenceTransformer("all-MiniLM-L6-v2")
    question_embedding = model.encode([question])[0].tolist()

    # –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —á–∞–Ω–∫–æ–≤
    print("üîé –ò—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏...")
    results = collection.query(
        query_embeddings=[question_embedding],
        n_results=top_k,
        include=["documents", "distances"]
    )

    # –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –ø—É—Å—Ç—ã–µ
    if not results or "documents" not in results or not results["documents"]:
        print("‚ö†Ô∏è –ù–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.")
        return

    documents = results["documents"][0]
    distances = results.get("distances", [None])[0]

    print(f"üìö –ù–∞–π–¥–µ–Ω–æ {len(documents)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤\n")

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —á–∞–Ω–∫–∏ –≤ –æ–¥–∏–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç
    print("üß© –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç...")
    context_parts = []
    for i, doc in tqdm(enumerate(documents)):
        distance = distances[i] if distances else "N/A"
        print(f"üîπ –ß–∞–Ω–∫ #{i + 1} (—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ: {distance}):\n{doc}\n")
        context_parts.append(doc.strip())

    global context
    context += "\n".join(context_parts)  # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞–º–∏


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –∫ –º–æ–¥–µ–ª–∏ —Å —Ü–µ–ø–æ—á–∫–æ–π —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–π
def query_with_thought_chain(question):
    global context
    prompt = f"""
    –¢—ã ‚Äî –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫. –û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º –ø–æ—è—Å–Ω–µ–Ω–∏–µ–º. –†–∞–∑–±–µ–π –ø—Ä–æ—Ü–µ—Å—Å –Ω–∞ —à–∞–≥–∏, –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ.
    –ö–æ–Ω—Ç–µ–∫—Å—Ç:
    {context}
    –í–æ–ø—Ä–æ—Å:
    {question}
    –û—Ç–≤–µ—Ç (—Å –ø–æ—è—Å–Ω–µ–Ω–∏–µ–º):
    """

    print("\nü§ñ –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –æ—Ç–≤–µ—Ç —É –º–æ–¥–µ–ª–∏...\n")
    response = ollama.chat(
        model="llama3",  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å LLaMA3
        messages=[{"role": "user", "content": prompt}]
    )

    answer = response["message"]["content"]

    # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –æ—Ç–≤–µ—Ç–æ–º
    update_context(question, answer)

    return answer


# –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –≤–æ–ø—Ä–æ—Å–∞–º–∏ –∏ –æ—Ç–≤–µ—Ç–∞–º–∏ –∏–∑ JSON
def integrate_qa_pairs(qa_pairs):
    global context
    for pair in qa_pairs:
        question = pair["question"]
        answer = pair["answer"]
        update_context(question, answer)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="RAG-–≤–æ–ø—Ä–æ—Å –∫ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –∫–æ–º–ø–∞–Ω–∏–∏")
    parser.add_argument("--collection", type=str, required=True, help="–ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –≤ ChromaDB")
    parser.add_argument("--question", type=str, required=True, help="–í–æ–ø—Ä–æ—Å –Ω–∞ —Ä—É—Å—Å–∫–æ–º")
    parser.add_argument("--qa-file", type=str, required=False, help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –ø–∞—Ä–∞–º–∏ –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON",
                        default="./data/qa_pairs.json")

    args = parser.parse_args()

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø–∞—Ä—ã –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç –∏–∑ JSON
    qa_pairs = load_qa_pairs(args.qa_file)

    # –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ–º –ø–∞—Ä—ã –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
    integrate_qa_pairs(qa_pairs)

    # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –≤ ChromaDB
    query_chromadb(args.collection, args.question)

    # –¢–µ–ø–µ—Ä—å –∑–∞–¥–∞–µ–º –≤–æ–ø—Ä–æ—Å —Å —É—á–µ—Ç–æ–º –≤—Å–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    answer = query_with_thought_chain(args.question)

    print("üìù –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:")
    print(answer)
```
