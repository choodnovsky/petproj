import streamlit as st
import json
import redis
from sentence_transformers import SentenceTransformer
import chromadb
from ollama import Client
from configparser import ConfigParser

# –ö–æ–Ω—Ñ–∏–≥
parser = ConfigParser()
parser.read("config.ini")

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Redis
redis_client = redis.Redis(host=parser.get("REDIS", "HOST"), port=int(parser.get("REDIS", "PORT")), decode_responses=True)

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Ollama
ollama = Client(host='http://ollama:11434')

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ ChromaDB
client = chromadb.HttpClient(
    host=parser.get("CHROMADB", "HOST"),
    port=int(parser.get("CHROMADB", "PORT")),
)
collection = client.get_collection("wiki_docs")

# –ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
model = SentenceTransformer("all-MiniLM-L6-v2")

# === –£—Ç–∏–ª–∏—Ç—ã ===

def query_chromadb(question, top_k=4):
    question_embedding = model.encode([question])[0].tolist()
    results = collection.query(
        query_embeddings=[question_embedding],
        n_results=top_k,
        include=["documents"]
    )
    documents = results["documents"][0] if results and results["documents"] else []
    return "\n".join(documents)

def save_context_to_redis(context_text):
    redis_client.rpush("context_memory", context_text)

def load_full_context():
    return "\n---\n".join(redis_client.lrange("context_memory", 0, -1))

def clear_memory():
    redis_client.delete("context_memory")
    keys = redis_client.keys("chatlog:*")
    for key in keys:
        redis_client.delete(key)
    st.session_state.chat_history = []
    st.session_state.show_fix_input = False

def save_chat_log(question, answer, rating=5, feedback=None):
    log_entry = {
        "question": question,
        "answer": answer,
        "rating": rating,
    }
    if feedback:
        log_entry["feedback"] = feedback

    redis_key = f"chatlog:{question[:100]}"
    redis_value = json.dumps(log_entry, ensure_ascii=False)
    redis_client.set(redis_key, redis_value)

    if rating >= 4:
        context_block = f"[–û—Ü–µ–Ω–∫–∞: {rating}] –û—Ç–≤–µ—Ç: {answer}"
        save_context_to_redis(context_block)

# === –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ ===

def info_helper():
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    if "show_fix_input" not in st.session_state:
        st.session_state.show_fix_input = False

    if st.button("–û—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å"):
        clear_memory()
        st.success("–ü–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞.")

    user_input = st.chat_input("–í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å")

    if user_input:
        if user_input.strip().lower() == "/clear":
            clear_memory()
            st.success("–ü–∞–º—è—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—á–∏—â–µ–Ω–∞.")
        else:
            with st.chat_message("user"):
                st.markdown(user_input)

            st.session_state.chat_history.append({"role": "user", "content": user_input})

            new_context = query_chromadb(user_input)
            full_context = load_full_context()

            messages = [
                {
                    "role": "system",
                    "content": (
                        "–¢—ã –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫, –æ–±—â–∞—é—â–∏–π—Å—è —Å—Ç—Ä–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. "
                        "–û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π. "
                        "–ï—Å–ª–∏ –≤ –±–∞–∑–µ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ ‚Äî –ø—Ä—è–º–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º, –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–π."
                    )
                },
                {
                    "role": "user",
                    "content": f"–í–æ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω–Ω—ã–µ —Ñ–∞–∫—Ç—ã, —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –≤ –ø–∞–º—è—Ç–∏:\n{full_context}"
                },
                {
                    "role": "user",
                    "content": f"–ê –≤–æ—Ç —Ñ–∞–∫—Ç—ã, –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã–µ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –ø–æ —Ç–µ–∫—É—â–µ–º—É –≤–æ–ø—Ä–æ—Å—É:\n{new_context}"
                },
                {
                    "role": "user",
                    "content": user_input
                }
            ] + st.session_state.chat_history

            response = ollama.chat(model="llama3", messages=messages)
            raw_answer = response["message"]["content"]

            st.session_state.chat_history.append({
                "role": "assistant",
                "raw_content": raw_answer,
                "content": raw_answer
            })

            with st.chat_message("assistant"):
                st.markdown(raw_answer)

    for i, msg in enumerate(st.session_state.chat_history):
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

            if msg["role"] == "assistant" and i == len(st.session_state.chat_history) - 1:
                col1, col2 = st.columns([1, 3])
                with col1:
                    if st.button("OK", key=f"ok_{i}"):
                        question = st.session_state.chat_history[i - 1]["content"]
                        answer = msg["raw_content"]
                        save_chat_log(question, answer, rating=5)
                        st.success("–û—Ç–≤–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω –∏ –¥–æ–±–∞–≤–ª–µ–Ω –≤ –ø–∞–º—è—Ç—å.")

                with col2:
                    st.markdown("### –û—Ü–µ–Ω–∫–∞:")
                    score = st.slider("–ù–∞—Å–∫–æ–ª—å–∫–æ –ø–æ–ª–µ–∑–µ–Ω –æ—Ç–≤–µ—Ç?", 1, 5, 5, key=f"rating_{i}")
                    feedback = None
                    if score < 4:
                        feedback = st.text_area("–ß—Ç–æ –±—ã–ª–æ –Ω–µ —Ç–∞–∫?", key=f"feedback_{i}")

                    if st.button("üìé –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ü–µ–Ω–∫—É", key=f"confirm_rating_{i}"):
                        question = st.session_state.chat_history[i - 1]["content"]
                        answer = msg["raw_content"]
                        save_chat_log(question, answer, rating=score, feedback=feedback)
                        st.success("–û—Ü–µ–Ω–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞.")
