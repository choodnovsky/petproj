import streamlit as st
import json
import os
from sentence_transformers import SentenceTransformer
import chromadb
from ollama import Client
from configparser import ConfigParser

# –ö–æ–Ω—Ñ–∏–≥
parser = ConfigParser()
parser.read("config.ini")

# –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
CONTEXT_FILE = "/usr/src/data/context_memory.txt"
CHAT_LOG_FILE = "/usr/src/data/chat_log.jsonl"

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Ollama
ollama = Client(host='http://ollama:11434')

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ ChromaDB
client = chromadb.HttpClient(
    host=parser.get("CHROMADB", "HOST"),
    port=int(parser.get("CHROMADB", "PORT")),
)

collection = client.get_collection("wiki_docs")

# –ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
model = SentenceTransformer("all-MiniLM-L6-v2")

# === –£—Ç–∏–ª–∏—Ç—ã ===

def query_chromadb(question, top_k=4):
    question_embedding = model.encode([question])[0].tolist()
    results = collection.query(
        query_embeddings=[question_embedding],
        n_results=top_k,
        include=["documents"]
    )
    documents = results["documents"][0] if results and results["documents"] else []
    return "\n".join(documents)

def save_context_to_file(context_text):
    os.makedirs(os.path.dirname(CONTEXT_FILE), exist_ok=True)
    with open(CONTEXT_FILE, "a", encoding="utf-8") as f:
        f.write(context_text + "\n---\n")

def load_full_context():
    if os.path.exists(CONTEXT_FILE):
        with open(CONTEXT_FILE, "r", encoding="utf-8") as f:
            return f.read()
    return ""

def save_chat_log(question, answer):
    os.makedirs(os.path.dirname(CHAT_LOG_FILE), exist_ok=True)
    log_entry = {"question": question, "answer": answer}
    with open(CHAT_LOG_FILE, "a", encoding="utf-8") as f:
        f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")

def clear_memory():
    if os.path.exists(CONTEXT_FILE):
        os.remove(CONTEXT_FILE)
    if os.path.exists(CHAT_LOG_FILE):
        os.remove(CHAT_LOG_FILE)
    st.session_state.chat_history = []
    st.session_state.show_fix_input = False

# === –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ ===

def info_helper():
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    if "show_fix_input" not in st.session_state:
        st.session_state.show_fix_input = False

    if st.button("–û—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å"):
        clear_memory()
        st.success("–ü–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞.")

    user_input = st.chat_input("–í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å")

    if user_input:
        if user_input.strip().lower() == "/clear":
            clear_memory()
            st.success("–ü–∞–º—è—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—á–∏—â–µ–Ω–∞.")
        else:
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤–æ–ø—Ä–æ—Å
            with st.chat_message("user"):
                st.markdown(user_input)

            st.session_state.chat_history.append({"role": "user", "content": user_input})

            new_context = query_chromadb(user_input)
            full_context = load_full_context()

            messages = [
                {
                    "role": "system",
                    "content": (
                        "–¢—ã –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫. –í—Å–µ–≥–¥–∞ –æ—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. "
                        "–ò—Å–ø–æ–ª—å–∑—É–π —Ü–µ–ø–æ—á–∫—É —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–π. –ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–æ—à–ª—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π.\n\n"
                        f"–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç:\n{full_context}"
                    )
                }
            ] + st.session_state.chat_history

            response = ollama.chat(model="llama3", messages=messages)
            raw_answer = response["message"]["content"]

            st.session_state.chat_history.append({
                "role": "assistant",
                "raw_content": raw_answer,
                "content": raw_answer + "\n\n_–ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –∫–∞–∂–µ—Ç—Å—è –Ω–µ—Ç–æ—á–Ω—ã–º, –Ω–∞–∂–º–∏—Ç–µ '–ò—Å–ø—Ä–∞–≤–∏—Ç—å' –Ω–∏–∂–µ. –Ø —É—á—Ç—É —ç—Ç–æ –≤ –±—É–¥—É—â–µ–º._"
            })

            with st.chat_message("assistant"):
                st.markdown(st.session_state.chat_history[-1]["content"])

    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
    for i, msg in enumerate(st.session_state.chat_history):
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

            if msg["role"] == "assistant" and i == len(st.session_state.chat_history) - 1:
                col1, col2 = st.columns([1, 3])
                with col1:
                    if st.button("OK", key=f"ok_{i}"):
                        question = st.session_state.chat_history[i - 1]["content"]
                        answer = msg["raw_content"]
                        save_context_to_file(answer)
                        save_chat_log(question, answer)
                        st.success("–û—Ç–≤–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω –∏ –¥–æ–±–∞–≤–ª–µ–Ω –≤ –ø–∞–º—è—Ç—å.")

                with col2:
                    if st.button("–ò—Å–ø—Ä–∞–≤–∏—Ç—å", key=f"fix_{i}"):
                        st.session_state.show_fix_input = True

                if st.session_state.show_fix_input:
                    fixed = st.text_area("–í–≤–µ–¥–∏—Ç–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç", key=f"fix_text_{i}")
                    if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ", key=f"save_fix_{i}"):
                        st.session_state.chat_history[i]["raw_content"] = fixed
                        st.session_state.chat_history[i]["content"] = (
                            fixed + "\n\n_–ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –∫–∞–∂–µ—Ç—Å—è –Ω–µ—Ç–æ—á–Ω—ã–º, –Ω–∞–∂–º–∏—Ç–µ '–ò—Å–ø—Ä–∞–≤–∏—Ç—å' –Ω–∏–∂–µ. –Ø —É—á—Ç—É —ç—Ç–æ –≤ –±—É–¥—É—â–µ–º._"
                        )
                        question = st.session_state.chat_history[i - 1]["content"]
                        save_context_to_file(fixed)
                        save_chat_log(question, fixed)
                        st.success("–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ.")
                        st.session_state.show_fix_input = False