from sentence_transformers import SentenceTransformer
import chromadb
from tqdm import tqdm
import argparse
import ollama


def query_chromadb(question: str, top_k: int = 7):
    # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Chroma
    client = chromadb.HttpClient(host="localhost", port=8000)
    collection = client.get_collection("lotr")

    # –≠–º–±–µ–¥–¥–∏–Ω–≥ –≤–æ–ø—Ä–æ—Å–∞
    model = SentenceTransformer("all-MiniLM-L6-v2")
    question_embedding = model.encode([question])[0].tolist()

    # –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —á–∞–Ω–∫–æ–≤
    print("üîé –ò—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏...")
    results = collection.query(
        query_embeddings=[question_embedding],
        n_results=top_k,
        include=["documents"]
    )

    documents = results["documents"][0]
    print(f"üìö –ù–∞–π–¥–µ–Ω–æ {len(documents)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤\n")

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —á–∞–Ω–∫–∏ –≤ –æ–¥–∏–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç
    print("üß© –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç...")
    context_parts = []
    for doc in tqdm(documents):
        context_parts.append(doc.strip())

    context = "\n---\n".join(context_parts)

    # –ü—Ä–æ–º–ø—Ç –∫ –º–æ–¥–µ–ª–∏
    prompt = f"""–û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—è –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∏–∂–µ.
–ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞, —Å–∫–∞–∂–∏ —á–µ—Å—Ç–Ω–æ, —á—Ç–æ –Ω–µ –∑–Ω–∞–µ—à—å.

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context}

–í–æ–ø—Ä–æ—Å: {question}
–û—Ç–≤–µ—Ç:"""

    print("ü§ñ –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –æ—Ç–≤–µ—Ç —É –º–æ–¥–µ–ª–∏...\n")
    response = ollama.chat(
        model="llama3",
        messages=[
            {"role": "user", "content": prompt}
        ]
    )

    print("üìù –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:\n")
    print(response["message"]["content"])


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="RAG-–≤–æ–ø—Ä–æ—Å –∫ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –ø–æ LOTR")
    parser.add_argument("--question", type=str, required=True, help="–í–æ–ø—Ä–æ—Å –Ω–∞ —Ä—É—Å—Å–∫–æ–º")
    args = parser.parse_args()
    query_chromadb(args.question)